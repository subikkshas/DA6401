# DA6401
DL Assignments

DA6401 Assignment 1: Neural Network Implementation for Fashion-MNIST Classification
Project Overview
This repository contains the implementation of a flexible feedforward neural network trained and evaluated on the Fashion-MNIST dataset. Various optimization algorithms, hyperparameter tuning strategies, and visualizations using WandB are implemented.

## Important Links

- **Weights & Biases (WandB) Project Dashboard:**  
[DA6401 Assignment 1 WandB Report](https://wandb.ai/subikksha-indian-institute-of-technology-madras/DA6401-Assignment-1/reports/DA6401-Assignment-1-Subikksha-DA24D004---VmlldzoxMTgxODg2Nw?accessToken=kn1n5y1dwof4g8c9uucoch4wejl8o85w0vlfwj75es98my1kweam9hh9irna31hy)

- **GitHub Repository:**  
[https://github.com/subikkshas/DA6401](https://github.com/subikkshas/DA6401)


Repository Structure
- [**`DLass1Q1.ipynb`**](https://github.com/subikkshas/DA6401/blob/main/DLass1Q1.ipynb): Dataset visualization and initial analysis.
- [**`DLass1Q2.ipynb`**](https://github.com/subikkshas/DA6401/blob/main/DLass1Q2.ipynb): Flexible feedforward neural network architecture implementation.
- [**`DLass1Q3.ipynb`**](https://github.com/subikkshas/DA6401/blob/main/DLass1Q3.ipynb): Backpropagation algorithm with optimization methods (SGD, Momentum, NAG, RMSprop, Adam, Nadam).
- [**`DLass1Q4to6.ipynb`**](https://github.com/subikkshas/DA6401/blob/main/DLass1Q4to6.ipynb): Hyperparameter tuning with WandB sweeps.
- [**`DLass1Q7.ipynb`**](https://github.com/subikkshas/DA6401/blob/main/DLass1Q7.ipynb): Confusion matrix visualization.
- [**`DLass1Q8.ipynb`**](https://github.com/subikkshas/DA6401/blob/main/DLass1Q8.ipynb): Cross-entropy vs. squared error loss comparison.
- [**`DLass1Q10.ipynb`**](https://github.com/subikkshas/DA6401/blob/main/DLass1Q10.ipynb): MNIST digit classification using insights from Fashion-MNIST.
- [**`Activations.ipynb`**](https://github.com/subikkshas/DA6401/blob/main/Activations.ipynb): Activation functions implementations.
- [**`Loss.ipynb`**](https://github.com/subikkshas/DA6401/blob/main/Loss.ipynb): Loss functions implementations.
- [**`Optimizers.ipynb`**](https://github.com/subikkshas/DA6401/blob/main/Optimizers.ipynb): Optimizer algorithms implementations.
- [**`Helper.ipynb`**](https://github.com/subikkshas/DA6401/blob/main/Helper.ipynb): Helper and utility functions.
- [**`Initializers.ipynb`**](https://github.com/subikkshas/DA6401/blob/main/Initializers.ipynb): Weight initialization methods.
- [**`Layers.ipynb`**](https://github.com/subikkshas/DA6401/blob/main/Layers.ipynb): Neural network layers implementation.
- [**`Network.ipynb`**](https://github.com/subikkshas/DA6401/blob/main/Network.ipynb): Neural network architecture definition.



## Setup Instructions

### Step 1: Clone the Repository
```bash
git clone https://github.com/subikkshas/DA6401.git
cd DA6401
```



### Step 1: Clone the Repository
```bash
git clone https://github.com/subikkshas/DA6401.git
cd DA6401
```


### Step 1: Clone the Repository
```bash
git clone https://github.com/subikkshas/DA6401.git
cd DA6401
```



